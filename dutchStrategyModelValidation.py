import fastf1
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Import extracted targeted parameters and simulation functions
try:
    from dutch_grand_prix_targeted_parameters import *
    PARAMETERS_LOADED = True
    print("Using extracted targeted parameters from dutch_grand_prix_targeted_parameters.py")
except ImportError:
    print("Warning: dutch_grand_prix_targeted_parameters.py not found. Run F1_Parameter_Extractor.py first.")
    PARAMETERS_LOADED = False

class F1ModelValidator:
    def __init__(self):
        self.actual_results = None
        self.actual_race_data = None
        self.simulation_results = None
        
    def load_actual_race_data(self, year=2025, gp_name='Dutch Grand Prix'):
        """Load actual 2025 Dutch GP race results and data from FastF1"""
        try:
            print(f"Loading {year} {gp_name} race data...")
            
            # load race session
            race_session = fastf1.get_session(year, gp_name, 'R')
            race_session.load()
            
            # load qualifying for grid positions
            quali_session = fastf1.get_session(year, gp_name, 'Q')
            quali_session.load()
            
            # extract race results
            results = race_session.results
            self.actual_results = results[['Abbreviation', 'Position', 'GridPosition', 'Time', 'Points']].copy()
            self.actual_results = self.actual_results.dropna(subset=['Position'])
            self.actual_results['Position'] = self.actual_results['Position'].astype(int)
            self.actual_results['GridPosition'] = self.actual_results['GridPosition'].astype(int)
            
            # extract lap data for strategy analysis
            laps = race_session.laps
            self.actual_race_data = {
                'laps': laps,
                'weather': self._analyze_weather_conditions(laps),
                'safety_cars': self._detect_safety_cars(laps),
                'strategies': self._extract_pit_strategies(laps),
                'total_laps': race_session.total_laps,
                'race_time': race_session.results['Time'].iloc[0] if not race_session.results.empty else None
            }
            
            print(f"Successfully loaded 2025 Dutch GP data for {len(self.actual_results)} drivers")
            print(f"Race winner: {self.actual_results.iloc[0]['Abbreviation']} from grid P{self.actual_results.iloc[0]['GridPosition']}")
            return True
            
        except Exception as e:
            print(f"Error loading 2025 Dutch GP race data: {e}")
            print("The 2025 Dutch GP may not have occurred yet or data may not be available in FastF1")
            return False
    
    def _analyze_weather_conditions(self, laps):
        """Analyze weather conditions during the race"""
        weather_info = {
            'dry_laps': 0,
            'intermediate_laps': 0,
            'wet_laps': 0,
            'rain_occurred': False,
            'weather_changes': 0
        }
        
        # count laps by compound type
        compound_counts = laps['Compound'].value_counts()
        
        dry_compounds = ['SOFT', 'MEDIUM', 'HARD']
        wet_compounds = ['INTERMEDIATE', 'WET']
        
        for compound in dry_compounds:
            if compound in compound_counts:
                weather_info['dry_laps'] += compound_counts[compound]
        
        for compound in wet_compounds:
            if compound in compound_counts:
                if compound == 'INTERMEDIATE':
                    weather_info['intermediate_laps'] += compound_counts[compound]
                else:
                    weather_info['wet_laps'] += compound_counts[compound]
        
        weather_info['rain_occurred'] = (weather_info['intermediate_laps'] + weather_info['wet_laps']) > 0
        
        # detect weather changes by looking at compound changes across the field
        total_laps = len(laps['LapNumber'].unique())
        weather_info['total_laps'] = total_laps
        weather_info['rain_percentage'] = (weather_info['intermediate_laps'] + weather_info['wet_laps']) / len(laps) * 100
        
        return weather_info
    
    def _detect_safety_cars(self, laps):
        """Detect safety car periods from lap time anomalies"""
        # calculate median lap time for each lap number
        lap_medians = laps.groupby('LapNumber')['LapTime'].median()
        
        # convert to seconds 
        lap_medians_seconds = lap_medians.dt.total_seconds()
        
        # calculate rolling median to establish baseline
        baseline = lap_medians_seconds.rolling(window=5, center=True).median()
        
        # identify laps significantly slower than baseline (potential SC/VSC)
        sc_threshold_factor = 1.25  # 25% slower than baseline
        potential_sc_laps = []
        
        for lap_num, lap_time in lap_medians_seconds.items():
            if not pd.isna(baseline.loc[lap_num]):
                if lap_time > baseline.loc[lap_num] * sc_threshold_factor:
                    potential_sc_laps.append(lap_num)
        
        return {
            'sc_laps': potential_sc_laps,
            'sc_occurred': len(potential_sc_laps) > 0,
            'sc_lap_count': len(potential_sc_laps),
            'sc_percentage': len(potential_sc_laps) / len(lap_medians) * 100 if len(lap_medians) > 0 else 0
        }
    
    def _extract_pit_strategies(self, laps):
        """Extract pit stop strategies for each driver"""
        strategies = {}
        
        for driver in laps['Driver'].unique():
            driver_laps = laps[laps['Driver'] == driver]
            stints = driver_laps.groupby('Stint')
            
            driver_strategy = []
            total_pit_stops = 0
            
            for stint_num, stint_data in stints:
                if len(stint_data) > 0:
                    compound = stint_data['Compound'].iloc[0] if not stint_data['Compound'].isna().all() else 'UNKNOWN'
                    stint_length = len(stint_data)
                    
                    driver_strategy.append({
                        'compound': compound,
                        'laps': stint_length,
                        'stint_number': stint_num
                    })
                    
                    if stint_num > 1:  # count pit stops (stint changes)
                        total_pit_stops += 1
            
            strategies[driver] = {
                'strategy': driver_strategy,
                'total_pit_stops': total_pit_stops,
                'strategy_type': self._classify_strategy(driver_strategy)
            }
            
        return strategies
    
    def _classify_strategy(self, strategy):
        """Classify strategy type based on number of stops and compounds"""
        if len(strategy) == 1:
            return "0-stop"
        elif len(strategy) == 2:
            compounds = [stint['compound'] for stint in strategy]
            return f"1-stop ({'-'.join(compounds)})"
        elif len(strategy) == 3:
            compounds = [stint['compound'] for stint in strategy]
            return f"2-stop ({'-'.join(compounds)})"
        else:
            return f"{len(strategy)-1}-stop"
    
    def generate_simulation_results(self, grid_positions=[1, 3, 5, 8, 10, 15], num_sims=1000):
        """Generate simulation results using Zandvoort parameters instead of hardcoded data"""
        
        if not PARAMETERS_LOADED:
            print("Warning: Cannot generate accurate simulation results without extracted parameters")
            print("Using fallback approximations - results will be less reliable")
            return self._generate_fallback_results(grid_positions)
        
        print("Generating simulation results using Zandvoort parameters and extracted data...")
        
        try:
            # Import from the updated Zandvoort simulation script
            import sys
            import os
            
            # Try to import the simulation functions
            from stochasticPitSimv3_Dutch import (
                all_strategies, run_monte_carlo_with_grid, compound_models,
                ZANDVOORT_PARAMS
            )
            
            # Run actual simulation with Zandvoort parameters
            simulation_data = run_monte_carlo_with_grid(
                all_strategies, compound_models, grid_positions, num_sims
            )
            
            # Convert to validation format
            validation_results = {}
            
            for grid_pos in grid_positions:
                validation_results[grid_pos] = {}
                
                for strategy_name, data in simulation_data[grid_pos].items():
                    validation_results[grid_pos][strategy_name] = {
                        'final_positions': data['final_positions'],
                        'points': data['points'],
                        'times': data['times']
                    }
            
            return validation_results
            
        except ImportError as e:
            print(f"Could not import Zandvoort simulation: {e}")
            print("Falling back to approximation method")
            return self._generate_fallback_results(grid_positions)
    
    def _generate_fallback_results(self, grid_positions):
        """Generate basic fallback results when simulation isn't available"""
        
        # Zandvoort-specific approximations
        base_race_time = 72 * 71  # 72 laps * ~71s per lap
        
        strategies = [
            "Gamble on Dry", "1-stop (M-H)", "1-stop (H-M)", "Wet Conservative",
            "Wet Aggressive", "2-stop (S-H-H)", "2-stop (M-M-H)", "2-stop (M-H-H)", "2-stop (S-M-H)"
        ]
        
        fallback_results = {}
        
        for grid_pos in grid_positions:
            fallback_results[grid_pos] = {}
            
            # Approximate position distributions for Zandvoort (harder overtaking)
            for strategy in strategies:
                # Model: harder to gain positions at Zandvoort
                base_position = max(1, grid_pos - np.random.randint(0, 2))  # Less position gain
                position_variance = max(0.8, grid_pos // 4)  # Reduced variance
                
                positions = np.random.normal(base_position, position_variance, 100)
                positions = np.clip(positions, 1, 20).astype(int)
                
                points = [self._get_f1_points(pos) for pos in positions]
                times = np.random.normal(base_race_time + grid_pos * 3, 25, 100)
                
                fallback_results[grid_pos][strategy] = {
                    'final_positions': positions.tolist(),
                    'points': points,
                    'times': times.tolist()
                }
        
        return fallback_results
    
    def _get_f1_points(self, position):
        """F1 points system"""
        points_map = {1: 25, 2: 18, 3: 15, 4: 12, 5: 10, 6: 8, 7: 6, 8: 4, 9: 2, 10: 1}
        return points_map.get(position, 0)
    
    def load_simulation_predictions(self, simulation_results=None):
        """Load simulation results - now generates them dynamically using Zandvoort parameters"""
        if simulation_results is None:
            # Generate results using Zandvoort parameters and extracted data
            simulation_results = self.generate_simulation_results()
        
        self.simulation_results = simulation_results
        print("Simulation results loaded for validation")
    
    def validate_position_predictions(self, grid_positions_to_check=[1, 3, 5, 8, 10, 15]):
        """Validate final position predictions against actual results"""
        if self.actual_results is None or self.simulation_results is None:
            print("Error: Missing actual results or simulation data")
            return None
        
        validation_results = {}
        
        print("\n" + "="*80)
        print("POSITION PREDICTION VALIDATION")
        print("="*80)
        
        # Determine if it was a wet race based on actual conditions
        weather = self.actual_race_data['weather'] if self.actual_race_data else {'rain_occurred': False}
        was_wet_race = weather['rain_occurred']
        
        print(f"Race conditions: {'Wet' if was_wet_race else 'Dry'}")
        
        for grid_pos in grid_positions_to_check:
            # find driver who started from this grid position
            actual_driver = self.actual_results[self.actual_results['GridPosition'] == grid_pos]
            
            if len(actual_driver) == 0:
                print(f"No driver found starting from grid position {grid_pos}")
                continue
                
            actual_final_pos = actual_driver['Position'].iloc[0]
            actual_points = actual_driver['Points'].iloc[0]
            driver_name = actual_driver['Abbreviation'].iloc[0]
            
            print(f"\nGrid P{grid_pos} - {driver_name}: Actual finish P{actual_final_pos} ({actual_points} points)")
            
            # get simulation predictions for this grid position
            if grid_pos in self.simulation_results:
                sim_data = self.simulation_results[grid_pos]
                
                # Filter strategies based on race conditions
                if was_wet_race:
                    # For wet races, consider wet strategies and weather-dependent strategies
                    filtered_strategies = {k: v for k, v in sim_data.items() 
                                         if 'Wet' in k or 'Gamble on Dry' in k}
                    print("Validating against wet/weather strategies only")
                else:
                    # For dry races, exclude wet strategies but keep dry tire strategies
                    filtered_strategies = {k: v for k, v in sim_data.items() 
                                         if 'Wet' not in k and 'Gamble on Dry' not in k}
                    print("Validating against dry strategies only")

                if not filtered_strategies:
                    print(f"No appropriate strategies found for {'wet' if was_wet_race else 'dry'} conditions")
                    continue
                
                # calculate prediction accuracy for each appropriate strategy
                strategy_accuracy = {}
                best_strategy = None
                best_accuracy = float('inf')
                
                for strategy, results in filtered_strategies.items():
                    predicted_positions = np.array(results['final_positions'])
                    predicted_points = np.array(results['points'])
                    
                    # calculate accuracy metrics
                    position_mae = np.mean(np.abs(predicted_positions - actual_final_pos))
                    position_rmse = np.sqrt(np.mean((predicted_positions - actual_final_pos)**2))
                    points_mae = np.mean(np.abs(predicted_points - actual_points))
                    
                    # probability that simulation predicted within ¬±2 positions
                    accuracy_within_2 = np.mean(np.abs(predicted_positions - actual_final_pos) <= 2) * 100
                    
                    mean_predicted_pos = np.mean(predicted_positions)
                    mean_predicted_points = np.mean(predicted_points)
                    
                    strategy_accuracy[strategy] = {
                        'position_mae': position_mae,
                        'position_rmse': position_rmse,
                        'points_mae': points_mae,
                        'accuracy_within_2_positions': accuracy_within_2,
                        'mean_predicted_position': mean_predicted_pos,
                        'mean_predicted_points': mean_predicted_points,
                        'position_error': mean_predicted_pos - actual_final_pos
                    }
                    
                    # best performing strategy
                    if position_mae < best_accuracy:
                        best_accuracy = position_mae
                        best_strategy = strategy
                
                validation_results[grid_pos] = {
                    'driver': driver_name,
                    'actual_position': actual_final_pos,
                    'actual_points': actual_points,
                    'strategy_accuracy': strategy_accuracy,
                    'best_strategy': best_strategy,
                    'best_mae': best_accuracy,
                    'race_conditions': 'wet' if was_wet_race else 'dry'
                }
                
                print(f"Best strategy prediction: {best_strategy} (MAE: {best_accuracy:.2f})")
                print(f"Predicted: P{strategy_accuracy[best_strategy]['mean_predicted_position']:.1f}, "
                      f"Actual: P{actual_final_pos}")
        
        return validation_results
    
    def validate_race_conditions(self):
        """Validate race condition predictions (weather, safety cars) against actual using Zandvoort parameters"""
        if self.actual_race_data is None:
            print("Error: No actual race data loaded")
            return None
        
        print("\n" + "="*80)
        print("RACE CONDITIONS VALIDATION")
        print("="*80)
        
        weather = self.actual_race_data['weather']
        safety_cars = self.actual_race_data['safety_cars']
        
        print(f"\nWeather Analysis:")
        print(f"Rain occurred: {weather['rain_occurred']}")
        print(f"Rain percentage: {weather['rain_percentage']:.1f}%")
        print(f"Dry laps: {weather['dry_laps']}")
        print(f"Intermediate laps: {weather['intermediate_laps']}")
        print(f"Wet laps: {weather['wet_laps']}")
        
        print(f"\nSafety Car Analysis:")
        print(f"Safety car occurred: {safety_cars['sc_occurred']}")
        print(f"SC/VSC laps: {safety_cars['sc_lap_count']}")
        print(f"SC percentage: {safety_cars['sc_percentage']:.1f}%")
        if safety_cars['sc_laps']:
            print(f"Suspected SC/VSC laps: {safety_cars['sc_laps']}")
        
        # compare with Zandvoort simulation parameters
        print(f"\nSimulation vs Actual:")
        
        # Use Zandvoort-specific probabilities
        sim_rain_prob = 0.30  # 30% rain probability for Zandvoort
        sim_sc_prob = 0.67    # 67% SC probability for Zandvoort
        sim_vsc_prob = 0.67   # 67% VSC probability for Zandvoort
        
        print(f"Zandvoort rain probability: {sim_rain_prob:.0%}")
        print(f"Zandvoort SC probability: {sim_sc_prob:.0%}")
        print(f"Zandvoort VSC probability: {sim_vsc_prob:.0%}")
        
        actual_rain_occurred = weather['rain_occurred']
        actual_sc_occurred = safety_cars['sc_occurred']
        print(f"Actual rain occurred: {'Yes' if actual_rain_occurred else 'No'}")
        print(f"Actual SC occurred: {'Yes' if actual_sc_occurred else 'No'}")
        
        # Calculate prediction accuracy for Zandvoort parameters
        rain_prediction_correct = (sim_rain_prob >= 0.5) == actual_rain_occurred
        sc_prediction_reasonable = True  # 67% is high, so SC occurring would be expected
        
        # Parameter quality assessment
        if PARAMETERS_LOADED:
            print(f"\nExtracted Parameter Quality:")
            
            for param_section in ['POSITION_PENALTIES', 'TIRE_PERFORMANCE', 'DRIVER_ERROR_RATES', 'DRS_EFFECTIVENESS']:
                if param_section in globals():
                    param_data = globals()[param_section]
                    if isinstance(param_data, dict):
                        total_samples = 0
                        if param_section == 'POSITION_PENALTIES':
                            total_samples = sum(pos_data.get('sample_size', 0) 
                                              for pos_data in param_data.values() 
                                              if isinstance(pos_data, dict))
                        elif param_section == 'TIRE_PERFORMANCE':
                            total_samples = sum(comp_data.get('sample_size', 0) 
                                              for comp_data in param_data.values()
                                              if isinstance(comp_data, dict))
                        elif param_section in ['DRIVER_ERROR_RATES', 'DRS_EFFECTIVENESS']:
                            total_samples = param_data.get('sample_size', 0)
                        
                        quality = 'Excellent' if total_samples > 200 else 'Good' if total_samples > 50 else 'Limited'
                        print(f"  {param_section}: {quality} (n={total_samples})")
        
        return {
            'weather': weather,
            'safety_cars': safety_cars,
            'rain_prediction_correct': rain_prediction_correct,
            'sc_prediction_reasonable': sc_prediction_reasonable,
            'parameter_source': 'extracted' if PARAMETERS_LOADED else 'fallback',
            'zandvoort_probabilities': {
                'rain': sim_rain_prob,
                'sc': sim_sc_prob,
                'vsc': sim_vsc_prob
            }
        }
    
    def validate_strategies(self):
        """Validate actual pit strategies against simulation strategy options"""
        if self.actual_race_data is None:
            print("Error: No actual race data loaded")
            return None
        
        print("\n" + "="*80)
        print("STRATEGY VALIDATION")
        print("="*80)
        
        strategies = self.actual_race_data['strategies']
        
        # analyze actual strategies used
        strategy_distribution = {}
        for driver, data in strategies.items():
            strategy_type = data['strategy_type']
            if strategy_type not in strategy_distribution:
                strategy_distribution[strategy_type] = 0
            strategy_distribution[strategy_type] += 1
        
        print(f"\nActual strategy distribution:")
        for strategy, count in sorted(strategy_distribution.items()):
            print(f"{strategy}: {count} drivers")
        
        # Check for WET tire usage (should be none in updated model)
        wet_tire_usage = 0
        for driver, data in strategies.items():
            for stint in data['strategy']:
                if stint['compound'] == 'WET':
                    wet_tire_usage += 1
        
        print(f"\nWET tire compound usage: {wet_tire_usage} stints")
        if wet_tire_usage == 0:
            print("‚úì Confirms WET tire removal from model is realistic")
        else:
            print("‚ö† Actual WET tire usage conflicts with updated model")
        
        # find most successful strategies
        strategy_results = {}
        for _, row in self.actual_results.iterrows():
            driver = row['Abbreviation']
            if driver in strategies:
                strategy_type = strategies[driver]['strategy_type']
                if strategy_type not in strategy_results:
                    strategy_results[strategy_type] = []
                strategy_results[strategy_type].append({
                    'position': row['Position'],
                    'grid': row['GridPosition'],
                    'points': row['Points']
                })
        
        print(f"\nStrategy effectiveness:")
        for strategy, results in strategy_results.items():
            avg_finish = np.mean([r['position'] for r in results])
            avg_points = np.mean([r['points'] for r in results])
            positions_gained = np.mean([r['grid'] - r['position'] for r in results])
            print(f"{strategy}: Avg finish P{avg_finish:.1f}, "
                  f"Avg points {avg_points:.1f}, "
                  f"Avg positions {'gained' if positions_gained > 0 else 'lost'} {abs(positions_gained):.1f}")
        
        return {
            'strategy_distribution': strategy_distribution,
            'strategy_results': strategy_results,
            'wet_tire_usage': wet_tire_usage
        }
    
    def validate_extracted_parameters(self):
        """Validate the extracted parameters against actual race characteristics"""
        if not PARAMETERS_LOADED:
            print("Cannot validate parameters - extraction file not available")
            return None
        
        print("\n" + "="*80)
        print("EXTRACTED PARAMETER VALIDATION")
        print("="*80)
        
        validation_results = {}
        
        # Validate tire performance against actual usage
        if self.actual_race_data and 'laps' in self.actual_race_data:
            laps = self.actual_race_data['laps']
            clean_laps = laps[
                (laps['TrackStatus'] == '1') &
                (~laps['PitOutTime'].notna()) &
                (~laps['PitInTime'].notna()) &
                (laps['LapTime'].notna()) &
                (laps['Compound'].notna())
            ]
            
            if len(clean_laps) > 0:
                actual_compound_usage = clean_laps['Compound'].value_counts()
                print(f"Actual tire compound usage:")
                for compound, count in actual_compound_usage.items():
                    print(f"  {compound}: {count} laps")
                    
                # Compare with extracted tire performance data
                if 'TIRE_PERFORMANCE' in globals():
                    print(f"\nExtracted tire performance (SOFT baseline):")
                    for compound in ['SOFT', 'MEDIUM', 'HARD']:
                        if compound in TIRE_PERFORMANCE:
                            offset = TIRE_PERFORMANCE[compound].get('offset', 0)
                            deg_rate = TIRE_PERFORMANCE[compound].get('degradation_rate', 0)
                            sample_size = TIRE_PERFORMANCE[compound].get('sample_size', 0)
                            print(f"  {compound}: {offset:+.3f}s vs SOFT, {deg_rate:.4f}s/lap deg (n={sample_size})")
        
        # Validate position penalties
        if 'POSITION_PENALTIES' in globals() and self.actual_results is not None:
            print(f"\nPosition penalty validation:")
            actual_position_changes = []
            for _, row in self.actual_results.iterrows():
                change = row['Position'] - row['GridPosition']
                actual_position_changes.append((row['GridPosition'], change))
            
            # Group by grid position
            grid_pos_changes = {}
            for grid_pos, change in actual_position_changes:
                if grid_pos not in grid_pos_changes:
                    grid_pos_changes[grid_pos] = []
                grid_pos_changes[grid_pos].append(change)
            
            for grid_pos in sorted(grid_pos_changes.keys())[:10]:  # First 10 positions
                actual_avg_change = np.mean(grid_pos_changes[grid_pos])
                extracted_penalty = POSITION_PENALTIES.get(grid_pos, {}).get('penalty', 0)
                
                # Higher penalties should correlate with less position gain
                print(f"  P{grid_pos}: Avg change {actual_avg_change:+.1f} positions, "
                      f"extracted penalty {extracted_penalty:.3f}s")
        
        return validation_results
    
    def create_validation_plots(self, validation_results):
        """Create visualization plots for validation results"""
        if validation_results is None:
            print("No validation results to plot")
            return
        
        # Increase figure size and adjust layout parameters
        fig, axes = plt.subplots(2, 2, figsize=(18, 14))
        parameter_source = 'Extracted Parameters + Zandvoort Specifics' if PARAMETERS_LOADED else 'Fallback Parameters + Zandvoort Specifics'
        fig.suptitle(f'2025 Dutch GP - Model Validation Results ({parameter_source})', fontsize=16, y=0.98)
        
        # Plot 1: Predicted vs Actual Positions
        ax1 = axes[0, 0]
        grid_positions = []
        actual_positions = []
        predicted_positions = []
        drivers = []
        
        for grid_pos, data in validation_results.items():
            grid_positions.append(grid_pos)
            actual_positions.append(data['actual_position'])
            # use best strategy prediction
            best_strategy = data['best_strategy']
            predicted_positions.append(data['strategy_accuracy'][best_strategy]['mean_predicted_position'])
            drivers.append(data['driver'])
        
        ax1.scatter(predicted_positions, actual_positions, s=120, alpha=0.8)
        ax1.plot([1, 20], [1, 20], 'r--', alpha=0.6, label='Perfect prediction', linewidth=2)
        ax1.set_xlabel('Predicted Position', fontsize=12)
        ax1.set_ylabel('Actual Position', fontsize=12)
        ax1.set_title('Predicted vs Actual Final Positions', fontsize=14, pad=20)
        ax1.legend(fontsize=11)
        ax1.grid(True, alpha=0.3)
        
        # add driver labels with better positioning
        for i, driver in enumerate(drivers):
            ax1.annotate(driver, (predicted_positions[i], actual_positions[i]), 
                        xytext=(8, 8), textcoords='offset points', fontsize=10, 
                        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))
        
        # Plot 2: Prediction Accuracy by Grid Position
        ax2 = axes[0, 1]
        mae_values = [data['best_mae'] for data in validation_results.values()]
        bars2 = ax2.bar(grid_positions, mae_values, alpha=0.8, color='steelblue')
        ax2.set_xlabel('Starting Grid Position', fontsize=12)
        ax2.set_ylabel('Mean Absolute Error (positions)', fontsize=12)
        ax2.set_title('Prediction Accuracy by Grid Position', fontsize=14, pad=20)
        ax2.grid(True, alpha=0.3)
        
        # Add value labels on bars
        for bar, val in zip(bars2, mae_values):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, 
                    f'{val:.2f}', ha='center', va='bottom', fontsize=10)
        
        # Plot 3: Strategy Performance Comparison
        ax3 = axes[1, 0]
        all_strategies = set()
        for data in validation_results.values():
            all_strategies.update(data['strategy_accuracy'].keys())
        
        strategy_mae = {strategy: [] for strategy in all_strategies}
        for data in validation_results.values():
            for strategy in all_strategies:
                if strategy in data['strategy_accuracy']:
                    strategy_mae[strategy].append(data['strategy_accuracy'][strategy]['position_mae'])
                else:
                    strategy_mae[strategy].append(np.nan)
        
        strategy_names = list(strategy_mae.keys())
        avg_mae = [np.nanmean(strategy_mae[strategy]) for strategy in strategy_names]
        
        # Shorten strategy names for better display
        short_names = []
        for name in strategy_names:
            if len(name) > 15:
                short_names.append(name[:12] + '...')
            else:
                short_names.append(name)
        
        bars3 = ax3.bar(range(len(short_names)), avg_mae, alpha=0.8, color='lightcoral')
        ax3.set_xlabel('Strategy', fontsize=12)
        ax3.set_ylabel('Average MAE', fontsize=12)
        ax3.set_title('Strategy Prediction Accuracy', fontsize=14, pad=20)
        ax3.set_xticks(range(len(short_names)))
        ax3.set_xticklabels(short_names, rotation=45, ha='right', fontsize=10)
        ax3.grid(True, alpha=0.3)
        
        # Plot 4: Position Changes (Grid vs Finish)
        ax4 = axes[1, 1]
        position_changes = [data['actual_position'] - grid_pos for grid_pos, data in validation_results.items()]
        colors = ['green' if x < 0 else 'red' for x in position_changes]
        bars4 = ax4.bar(grid_positions, position_changes, alpha=0.8, color=colors)
        ax4.axhline(y=0, color='black', linestyle='-', alpha=0.5, linewidth=2)
        ax4.set_xlabel('Starting Grid Position', fontsize=12)
        ax4.set_ylabel('Position Change (+ = lost positions)', fontsize=12)
        ax4.set_title('Actual Position Changes in Race', fontsize=14, pad=20)
        ax4.grid(True, alpha=0.3)
        
        # Add value labels on bars
        for bar, val in zip(bars4, position_changes):
            y_pos = bar.get_height() + (0.2 if val >= 0 else -0.4)
            ax4.text(bar.get_x() + bar.get_width()/2, y_pos, 
                    f'{val:+.0f}', ha='center', va='bottom' if val >= 0 else 'top', fontsize=10)
        
        # Adjust layout to prevent overlapping
        plt.subplots_adjust(left=0.08, bottom=0.12, right=0.95, top=0.90, wspace=0.25, hspace=0.35)
        plt.show()
    
    def generate_comprehensive_validation_report(self):
        """Generate a comprehensive validation report including Zandvoort-specific parameters"""
        if self.actual_results is None:
            print("Error: No actual race data loaded")
            return
        
        print("\n" + "="*80)
        print("2025 DUTCH GP COMPREHENSIVE VALIDATION REPORT")
        print("="*80)
        
        # Parameter source and quality
        print(f"\nPARAMETER SOURCE:")
        if PARAMETERS_LOADED:
            print("‚úì Using extracted targeted parameters from dutch_grand_prix_targeted_parameters.py")
            
            # Display key extracted parameters
            print(f"\nEXTRACTED PARAMETERS SUMMARY:")
            
            if 'TIRE_PERFORMANCE' in globals():
                print(f"Tire Performance (SOFT baseline):")
                for compound in ['SOFT', 'MEDIUM', 'HARD']:
                    if compound in TIRE_PERFORMANCE:
                        offset = TIRE_PERFORMANCE[compound].get('offset', 0)
                        deg_rate = TIRE_PERFORMANCE[compound].get('degradation_rate', 0)
                        sample_size = TIRE_PERFORMANCE[compound].get('sample_size', 0)
                        print(f"  {compound}: {offset:+.3f}s vs SOFT, {deg_rate:.4f}s/lap deg (n={sample_size})")
            
            if 'POSITION_PENALTIES' in globals():
                penalty_samples = sum(pos_data.get('sample_size', 0) 
                                    for pos_data in POSITION_PENALTIES.values() 
                                    if isinstance(pos_data, dict))
                print(f"Position Penalties: {len(POSITION_PENALTIES)} positions covered, {penalty_samples} total samples")
            
            if 'DRIVER_ERROR_RATES' in globals():
                for condition in ['dry', 'wet']:
                    if condition in DRIVER_ERROR_RATES:
                        error_rate = DRIVER_ERROR_RATES[condition].get('base_error_rate', 0)
                        sample_size = DRIVER_ERROR_RATES[condition].get('sample_size', 0)
                        print(f"Driver Error Rate ({condition}): {error_rate:.4f} (n={sample_size})")
            
            if 'DRS_EFFECTIVENESS' in globals():
                drs_advantage = DRS_EFFECTIVENESS.get('median_advantage', 0)
                drs_usage = DRS_EFFECTIVENESS.get('usage_probability', 0)
                drs_samples = DRS_EFFECTIVENESS.get('sample_size', 0)
                print(f"DRS Effectiveness: {drs_advantage:.3f}s advantage, {drs_usage:.2f} usage prob (n={drs_samples})")
            
        else:
            print("‚ö† Using fallback parameters - run F1_Parameter_Extractor.py for better accuracy")
        
        print(f"\nZANDVOORT-SPECIFIC PARAMETERS:")
        print(f"Base Pace: 71.0s (Zandvoort lap time)")
        print(f"Race Distance: 72 laps")
        print(f"Rain Probability: 30% (coastal Netherlands pattern)")
        print(f"Safety Car Probability: 67% (banked corners, close barriers)")
        print(f"VSC Probability: 67% (high incident rate)")
        print(f"Pit Stop Time Loss: 21.52s (measured pit lane)")
        print(f"Fuel Consumption: 109kg / 72 laps = 1.514 kg/lap")
        print(f"Fuel Effect: 0.035s/kg (standard F1)")
        
        print(f"\nWET WEATHER STRATEGY UPDATES:")
        print("- Removed WET tire compound (never used in practice)")
        print("- Wet strategies now use only INTERMEDIATE compound")
        print("- More realistic wet weather tire allocation")
        
        print(f"\nVALIDATION WORKFLOW:")
        print("1. Load actual 2025 Dutch GP race data")
        print("2. Generate simulation predictions using Zandvoort + extracted parameters")
        print("3. Compare predictions against actual race outcomes")
        print("4. Assess parameter quality and prediction accuracy")
        
        # Detailed instructions
        print(f"\nTO RUN COMPLETE VALIDATION:")
        print("# Step 1: Ensure parameter extraction is complete")
        print("python F1_Parameter_Extractor.py 'Dutch Grand Prix'")
        print()
        print("# Step 2: Run validation with actual race data")
        print("validator = F1ModelValidator()")
        print("if validator.load_actual_race_data(2025, 'Dutch Grand Prix'):")
        print("    validator.load_simulation_predictions()")
        print("    position_validation = validator.validate_position_predictions()")
        print("    conditions_validation = validator.validate_race_conditions()")
        print("    strategy_validation = validator.validate_strategies()")
        print("    parameter_validation = validator.validate_extracted_parameters()")
        print("    validator.create_validation_plots(position_validation)")
        print("else:")
        print("    print('2025 Dutch GP race data not yet available')")
        
        print(f"\nVALIDATION METRICS:")
        print("- Position Prediction Accuracy: MAE in final positions vs Zandvoort simulation")
        print("- Weather Prediction: 30% rain probability vs actual conditions")
        print("- Safety Car Prediction: 67% SC/VSC rates vs actual incidents")
        print("- Strategy Effectiveness: Updated wet strategies (no WET tire) vs actual usage")
        print("- Parameter Quality: Extracted vs fallback parameter reliability")
        
        print(f"\nEXPECTED ACCURACY LEVELS:")
        if PARAMETERS_LOADED:
            # Calculate expected accuracy based on parameter quality
            total_samples = 0
            param_count = 0
            
            for param_name in ['POSITION_PENALTIES', 'TIRE_PERFORMANCE', 'DRIVER_ERROR_RATES', 'DRS_EFFECTIVENESS']:
                if param_name in globals():
                    param_data = globals()[param_name]
                    if isinstance(param_data, dict):
                        if param_name == 'POSITION_PENALTIES':
                            samples = sum(pos_data.get('sample_size', 0) 
                                        for pos_data in param_data.values() 
                                        if isinstance(pos_data, dict))
                        elif param_name == 'TIRE_PERFORMANCE':
                            samples = sum(comp_data.get('sample_size', 0) 
                                        for comp_data in param_data.values()
                                        if isinstance(comp_data, dict))
                        else:
                            samples = param_data.get('sample_size', 0)
                        
                        if samples > 0:
                            total_samples += samples
                            param_count += 1
            
            if param_count > 0:
                avg_sample_size = total_samples / param_count
                if avg_sample_size > 100:
                    expected_accuracy = "High (¬±1-2 positions)"
                elif avg_sample_size > 50:
                    expected_accuracy = "Good (¬±2-3 positions)"
                elif avg_sample_size > 20:
                    expected_accuracy = "Moderate (¬±3-4 positions)"
                else:
                    expected_accuracy = "Limited (¬±4+ positions)"
                
                print(f"Expected Position Prediction Accuracy: {expected_accuracy}")
                print(f"  Based on average sample size: {avg_sample_size:.0f}")
            
        else:
            print("Expected Accuracy: Limited (¬±4+ positions) - using fallback parameters")
        
        print(f"\nZANDVOORT-SPECIFIC LIMITATIONS:")
        print("- Overtaking difficulty may vary with car performance differences")
        print("- Weather patterns at coastal tracks can be unpredictable")
        print("- Banked corner effects on tire degradation are approximated")
        print("- Track evolution rate may differ from historical data")
        if not PARAMETERS_LOADED:
            print("- Using estimated parameters instead of track-specific extracted data")

def main():
    """Main function to run the validation"""
    validator = F1ModelValidator()
    
    print("F1 MODEL VALIDATOR FOR DUTCH GP")
    print("=" * 40)
    
    # Check if we have extracted parameters
    if not PARAMETERS_LOADED:
        print("‚ö† Warning: No extracted targeted parameters found.")
        print("For best accuracy, run F1_Parameter_Extractor.py first:")
        print("python F1_Parameter_Extractor.py 'Dutch Grand Prix'")
        print("\nProceeding with fallback parameters...")
    
    # Try to load actual 2025 Dutch GP data
    print("\nAttempting to load 2025 Dutch GP race data...")
    if not validator.load_actual_race_data(2025, 'Dutch Grand Prix'):
        print("\n2025 Dutch GP data not available yet.")
        print("This validation script will be ready to run once the race occurs.")
        
        # Show what the validation would look like
        validator.generate_comprehensive_validation_report()
        return
    
    # If we have actual race data, run full validation
    print("\nüèÅ 2025 Dutch GP data found! Running full validation...")
    
    # Generate simulation results using Zandvoort parameters and extracted data
    validator.load_simulation_predictions()
    
    # Run all validation components
    position_validation = validator.validate_position_predictions()
    conditions_validation = validator.validate_race_conditions()
    strategy_validation = validator.validate_strategies()
    parameter_validation = validator.validate_extracted_parameters()
    
    # Create visualization plots
    if position_validation:
        validator.create_validation_plots(position_validation)
    
    # Generate comprehensive report
    validator.generate_comprehensive_validation_report()
    
    # Summary of validation results
    if position_validation:
        print(f"\nüìä VALIDATION SUMMARY:")
        total_mae = np.mean([data['best_mae'] for data in position_validation.values()])
        print(f"Average Position Prediction Error: {total_mae:.2f} positions")
        
        if total_mae <= 2.0:
            print("üéØ Excellent prediction accuracy!")
        elif total_mae <= 3.0:
            print("‚úÖ Good prediction accuracy")
        elif total_mae <= 4.0:
            print("‚ö† Moderate prediction accuracy")
        else:
            print("‚ùå Poor prediction accuracy - consider parameter refinement")
    
    if conditions_validation:
        weather_correct = conditions_validation.get('rain_prediction_correct', False)
        sc_reasonable = conditions_validation.get('sc_prediction_reasonable', False)
        print(f"Weather prediction (30% rain): {'‚úÖ Reasonable' if not weather_correct or conditions_validation['zandvoort_probabilities']['rain'] < 0.5 else '‚ùå Incorrect'}")
        print(f"Safety Car prediction (67%): {'‚úÖ Expected with high probability' if sc_reasonable else '‚ùå Unexpected result'}")
    
    if strategy_validation:
        wet_tire_usage = strategy_validation.get('wet_tire_usage', 0)
        print(f"WET tire compound usage: {wet_tire_usage} stints")
        if wet_tire_usage == 0:
            print("‚úÖ WET tire removal from model validated")
        else:
            print("‚ö† Model may need WET tire strategy adjustment")

if __name__ == "__main__":
    main()